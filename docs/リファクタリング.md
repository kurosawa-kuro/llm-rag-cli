æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚ã„ã¾ã®è¨­è¨ˆã¯ã€Œæ©Ÿèƒ½ã¯æƒã£ã¦ã„ã‚‹ã€ã®ã§ã€æ¬¡ã¯ **â€œä¿å®ˆã§ãã‚‹å½¢â€ ã«å¯„ã›ã‚‹**ã®ãŒæ­£è§£ã§ã™ã€‚ä¸‹ã«ã€CLIå‹RAGã‚’å´©ã•ãšã«é€²ã‚ã‚‰ã‚Œã‚‹ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ–¹é‡ã¨ã€å…·ä½“çš„ãªä½œæ¥­é †ï¼ˆå£Šã—ã«ãã„é †ï¼‰ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

---

## 1) ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®ã‚´ãƒ¼ãƒ«ï¼ˆã‚³ãƒ¼ãƒ‰æ•´ç†ã®è»¸ï¼‰

å„ªå…ˆé †ä½ã¯ã“ã®é †ãŒå®‰å…¨ã§ã™ã€‚

1. **å¢ƒç•Œã‚’ã¯ã£ãã‚Šã•ã›ã‚‹**

   * â€œãƒ‰ãƒ¡ã‚¤ãƒ³(çŠ¶æ…‹/çµæœ)â€ ã¨ â€œå¤–éƒ¨(LLM/DB/ãƒ¢ãƒ‡ãƒ«)â€ ã‚’åˆ†é›¢
2. **ä¾å­˜ã‚’æ³¨å…¥ã§ãã‚‹å½¢ã«ã™ã‚‹**ï¼ˆãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§UPï¼‰

   * ã€Œã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚’æ¨ã¦ã‚‹ã€ã®ã§ã¯ãªãã€ã¾ãš â€œã‚³ãƒ³ãƒ†ãƒŠ/ãƒ•ã‚¡ã‚¯ãƒˆãƒªçµŒç”±â€ ã«å¯„ã›ã‚‹
3. **I/O ã¨ç´”ç²‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ†ã‘ã‚‹**

   * ingest/ask ã®CLIã¯è–„ãã€å†…éƒ¨ã¯é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹ã«å¯„ã›ã‚‹
4. **å‹ã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’å›ºå®šã™ã‚‹**

   * dictã®å¤šç”¨ã‚’ã‚„ã‚ã€`dataclass` / `TypedDict` / `pydantic` ã‚’å°å…¥
5. **ãƒ­ã‚°/ä¾‹å¤–/è¨­å®š**ã®ä¸€è²«æ€§ã‚’å–ã‚‹

   * â€œprintâ€ ã§ã¯ãªã â€œloggerâ€ã€ä¾‹å¤–ã¯æ¡ã‚Šã¤ã¶ã•ãªã„

---

## 2) ã¾ãšã‚„ã‚‹ã¹ãã€Œæ§‹é€ ã€æ•´ç†ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ãƒ»è²¬å‹™ï¼‰

ã„ã¾ã® `app/` ã¯è‰¯ã„ã§ã™ãŒã€**è²¬å‹™å˜ä½ã§ã‚µãƒ–ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–**ã™ã‚‹ã¨æ€¥ã«èª­ã¿ã‚„ã™ããªã‚Šã¾ã™ã€‚

ä¾‹ï¼ˆãŠã™ã™ã‚ï¼‰:

```text
app/
  __init__.py
  cli/
    ingest_cli.py
    ask_cli.py
    evaluate_cli.py
  core/
    config.py
    types.py          # RAGState, SearchResult ç­‰ã®å‹
    errors.py
    logging.py
  infra/
    db.py
    embeddings.py
    llm.py
    reranker.py
  pipeline/
    chunking.py
    ingest.py
    retrieval.py      # vector search
    prompting.py      # prompt builder
    graph.py
  eval/
    metrics.py
    evaluate.py
```

* `cli/` ã¯ **å¼•æ•°è§£æã—ã¦å‘¼ã¶ã ã‘**
* `infra/` ã¯ **é‡ã„ä¾å­˜ï¼ˆDB/ãƒ¢ãƒ‡ãƒ«ï¼‰**
* `pipeline/` ã¯ **å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯**
* `core/` ã¯ **å…±é€šï¼ˆè¨­å®š/å‹/ä¾‹å¤–/ãƒ­ã‚°ï¼‰**

ã“ã®åˆ†é›¢ã ã‘ã§ã€Œã©ã“ã‚’è§¦ã‚‹ã¨ä½•ãŒå£Šã‚Œã‚‹ã‹ã€ãŒæ¿€æ¸›ã—ã¾ã™ã€‚

---

## 3) ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®â€œæ‰±ã„â€ã‚’å¤‰ãˆã‚‹ï¼ˆæ¨ã¦ãšã«æ”¹å–„ï¼‰

ç¾çŠ¶ã® `_llm` `_embeddings` `_vectorstore` ã¯å®Ÿç”¨ä¸ŠOKã§ã™ã€‚
ãŸã ã— **importæ™‚ç‚¹ã§å‰¯ä½œç”¨ãŒå‡ºã‚„ã™ã„**ã®ãŒæ¬ ç‚¹ãªã®ã§ã€æ¬¡ã«å¯„ã›ã‚‹ã¨å®‰å®šã—ã¾ã™ã€‚

### æ¨å¥¨ï¼šAppContainerï¼ˆç°¡æ˜“DIï¼‰ã‚’å°å…¥

* â€œå¿…è¦ãªã¨ãã«åˆæœŸåŒ–â€ ã¯ç¶­æŒ
* ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¯ container ã®ä¸­ã«é–‰ã˜è¾¼ã‚ã‚‹
* ãƒ†ã‚¹ãƒˆã¯ container ã‚’å·®ã—æ›¿ãˆã‚‹ã ã‘ã§æ¸ˆã‚€

ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆæ–¹é‡ï¼‰:

* `core/container.py` ã‚’ä½œã‚Šã€`get_llm()` ç­‰ã‚’ **containerãƒ¡ã‚½ãƒƒãƒ‰**ã¸ç§»å‹•
* `graph.py` ã‚„ `ask.py` ã¯ container ã‚’å—ã‘å–ã‚‹ï¼ˆä¾å­˜æ³¨å…¥ï¼‰

> ã“ã‚Œã§ã€Œã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãŒæ•£ã‚‰ã°ã£ã¦ã„ã¦è¿½ãˆãªã„ã€ãŒè§£æ¶ˆã—ã¾ã™ã€‚

---

## 4) çŠ¶æ…‹ãƒ»æˆ»ã‚Šå€¤ã‚’ â€œdictâ€ ã‹ã‚‰å‹ã¸ï¼ˆå£Šã‚Œã‚‹å‰ã«å›ºå®šï¼‰

ã„ã¾ä¸€ç•ªäº‹æ•…ã‚Šã‚„ã™ã„ã®ã¯ã“ã“ã§ã™ã€‚

### 4.1 Searchçµæœã®å‹ã‚’å›ºå®š

`ask.search()` ãŒè¿”ã™ `list[dict]` ã¯ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æã§å£Šã‚Œã‚„ã™ã„ã®ã§ã€ã¾ãšã“ã‚Œã‚’å›ºå®šã€‚

* `SearchHit(content: str, source: str, score: float | None, metadata: dict)` ãªã©
* rerank ã‚‚ `List[Document]` or `List[SearchHit]` ã®ã©ã¡ã‚‰ã‹ã«çµ±ä¸€

### 4.2 RAGStateã‚’dataclassåŒ–

LangGraphã®stateã¯ dict ã§ã‚‚å‹•ãã¾ã™ãŒã€**é–‹ç™ºä½“é¨“ãŒæ®µé•ã„**ã«ãªã‚Šã¾ã™ã€‚

* `@dataclass` ã§ `query, documents, reranked_documents, contexts, prompt, answer, sources`
* ãƒãƒ¼ãƒ‰ã¯ã€ŒStateã‚’å—ã‘ã¦ Stateã‚’è¿”ã™ã€ã ã‘ã«çµ±ä¸€

---

## 5) graphãƒãƒ¼ãƒ‰ã‚’ â€œç´”ç²‹é–¢æ•°â€ ã«å¯„ã›ã‚‹ï¼ˆãƒ†ã‚¹ãƒˆæœ€å¼·åŒ–ï¼‰

ä»Šã® `retrieve/rerank/generate` ã¯è²¬å‹™ãŒæ˜ç¢ºãªã®ã§ã€æ¬¡ã®å½¢ãŒç†æƒ³ã§ã™ã€‚

* ãƒãƒ¼ãƒ‰å†…ã§ `get_llm()` ã¨ã‹ã‚’å‘¼ã°ãªã„
* ä¾å­˜ã¯å¤–ã‹ã‚‰æ¸¡ã™ï¼ˆcontainerçµŒç”±ã§ã‚‚OKï¼‰

ä¾‹ï¼š

* `retrieve(state, retriever) -> state`
* `rerank(state, reranker) -> state`
* `generate(state, llm, prompt_builder) -> state`

ã“ã‚Œã§ãƒ†ã‚¹ãƒˆãŒã€Œãƒ¢ãƒƒã‚¯ã‚’æ¸¡ã™ã ã‘ã€ã«ãªã‚Šã€ãƒ†ã‚¹ãƒˆé‡ã‚‚æ¸›ã‚‰ã›ã¾ã™ï¼ˆ250ä»¶ã‚’ç¶­æŒã—ã¤ã¤ä¿å®ˆæ€§UPï¼‰ã€‚

---

## 6) Promptçµ„ã¿ç«‹ã¦ã‚’ç‹¬ç«‹ã•ã›ã‚‹ï¼ˆæ”¹è‰¯ãŒé€Ÿããªã‚‹ï¼‰

`generate_node` ã«ãƒ™ã‚¿æ›¸ãã•ã‚Œã‚„ã™ã„ã®ã§ã€ã“ã“ã‚’åˆ†é›¢ã™ã‚‹ã¨ â€œå›ç­”å“è³ªæ”¹å–„â€ ã®å®Ÿé¨“ãŒã—ã‚„ã™ã„ã§ã™ã€‚

* `pipeline/prompting.py`

  * `build_prompt(query: str, contexts: list[str]) -> str`
  * â€œã‚½ãƒ¼ã‚¹ã®å‡ºã—æ–¹â€â€œå¼•ç”¨ãƒ«ãƒ¼ãƒ«â€â€œä¸è¶³æ™‚ã®è¿”ç­”â€ ã‚’ã“ã“ã§ä¸€å…ƒç®¡ç†

---

## 7) ingestã®è²¬å‹™åˆ†è§£ï¼ˆæ¬¡ã®æ‹¡å¼µãŒæ¥½ï¼‰

`ingest.py` ã¯ã‚„ã‚ŠãŒã¡ã§ã™ãŒè‚¥å¤§åŒ–ã—ã‚„ã™ã„ã®ã§ã€æ¬¡ã§åˆ†ã‘ã‚‹ã¨æ‹¡å¼µã«å¼·ã„ã§ã™ã€‚

* `loaders/`ï¼ˆã¾ãŸã¯ `pipeline/ingest.py` å†…ã§é–¢æ•°åˆ†å‰²ï¼‰

  * `load_pdf_pages()`
  * `load_csv_rows()`
* `chunkers/`

  * `chunk_pdf_text()`
  * `chunk_csv_text()`
* `writers/`

  * `add_documents(vectorstore, docs)`

ã€ŒPDFã ã‘å‡¦ç†ã—ãŸã„ã€ã€ŒCSVã ã‘å·®åˆ†å–ã‚Šè¾¼ã¿ã€ã¿ãŸã„ãªæ©Ÿèƒ½è¿½åŠ ãŒã»ã¼ç„¡æ–™ã«ãªã‚Šã¾ã™ã€‚

---

## 8) è¨­å®šç®¡ç†ã‚’ â€œpydantic settingsâ€ ã«å¯„ã›ã‚‹ï¼ˆç’°å¢ƒå¤‰æ•°åœ°ç„ã‚’çµ‚ã‚ã‚‰ã›ã‚‹ï¼‰

`config.py` ã® `get_db_config()` ã¯æ­£ã—ã„æ–¹å‘æ€§ã§ã™ã€‚æ¬¡ã®æ®µéšã¯ï¼š

* `RagSettings`ï¼ˆpydanticï¼‰ã§ `int` ãƒ‘ãƒ¼ã‚¹ãƒ»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ»ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸€æœ¬åŒ–
* ä¾‹ï¼š`CHUNK_OVERLAP >= 0`, `CHUNK_SIZE > 0`, `RERANK_TOP_K <= SEARCH_K` ãªã©

è¨­å®šã®æ•´åˆæ€§ã‚’èµ·å‹•æ™‚ã«æ¤œè¨¼ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

---

## 9) â€œãƒ­ã‚°â€ ã¨ â€œä¾‹å¤–â€ ã‚’çµ±ä¸€ï¼ˆé‹ç”¨ã®ãŸã‚ï¼‰

CPUæ¨è«– + pgvector ã¯ã€è©°ã¾ã‚‹ã¨åŸå› ãŒè¦‹ãˆã«ãã„ã§ã™ã€‚

* `core/logging.py` ã‚’ä½œã‚Š `logger = logging.getLogger("rag")`
* ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆã ã‘infoã§å‡ºã™ï¼ˆä¾‹ï¼šingestä»¶æ•°ã€æ¤œç´¢ä»¶æ•°ã€rerankä»¶æ•°ã€ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ãªã©ï¼‰
* ä¾‹å¤–ã¯æ¡ã‚Šã¤ã¶ã•ãšã€CLIå±¤ã§æ•´å½¢ã—ã¦çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™

  * `core/errors.py` ã« `RagError` ã‚’ä½œã‚Šã€å¤–éƒ¨ä¾‹å¤–ã¯ `raise RagError(...) from e`

---

## 10) å®Ÿè¡Œé †ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆå£Šã—ã«ãã„é †ï¼‰

ã“ã®é †ã§ã‚„ã‚‹ã¨å®‰å…¨ã§ã™ï¼ˆãƒ†ã‚¹ãƒˆãŒé€šã‚Šç¶šã‘ã‚„ã™ã„ï¼‰ã€‚

1. **ãƒ•ã‚©ãƒ«ãƒ€å†ç·¨ï¼ˆcli/core/infra/pipeline/evalï¼‰**ï¼šimportãƒ‘ã‚¹èª¿æ•´ã®ã¿
2. **prompting.py åˆ†é›¢**ï¼šgenerate_nodeã‹ã‚‰åˆ‡ã‚Šå‡ºã™
3. **Searchçµæœã®å‹å›ºå®š**ï¼ˆTypedDict â†’ dataclassã¸ï¼‰
4. **RAGState dataclassåŒ–**ï¼ˆLangGraph stateã®å—ã‘æ¸¡ã—ã‚’çµ±ä¸€ï¼‰
5. **containerå°å…¥**ï¼ˆé‡ã„ä¾å­˜ã‚’é›†ç´„ï¼‰
6. **graphãƒãƒ¼ãƒ‰ç´”ç²‹é–¢æ•°åŒ–**ï¼ˆä¾å­˜ã‚’å¼•æ•°ã¸ï¼‰
7. **pydantic settingså°å…¥**ï¼ˆè¨­å®šã®æ¤œè¨¼å«ã‚€ï¼‰
8. **ãƒ­ã‚°/ä¾‹å¤–ã®çµ±ä¸€**
9. **ingestè²¬å‹™åˆ†å‰²**ï¼ˆå·®åˆ†å–ã‚Šè¾¼ã¿ç­‰ã®æ‹¡å¼µã«å‚™ãˆã‚‹ï¼‰

---

## 11) ä»•ä¸Šã’ã®â€œå“è³ªâ€æ”¹å–„ï¼ˆä»»æ„ã ãŒåŠ¹ãï¼‰

* `make lint` ã‚’ `ruff` + `mypy` ã«ç½®ãæ›ãˆã‚‹ï¼ˆæ§‹æ–‡ãƒã‚§ãƒƒã‚¯ä»¥ä¸Šã«åŠ¹ãï¼‰
* ãƒ†ã‚¹ãƒˆã®é‡è¤‡ã‚’æ¸›ã‚‰ã™ï¼š

  * â€œãƒãƒ¼ãƒ‰å˜ä½“ãƒ†ã‚¹ãƒˆâ€ ã¨ â€œE2Eï¼ˆãƒ¢ãƒƒã‚¯ï¼‰â€ ã®2å±¤ã«æ•´ç†
* `Document` ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ã¯å®šæ•°åŒ–ï¼ˆ`SOURCE_KEY = "source"` ãªã©ï¼‰

å¤§å¤‰ã‚ˆãæ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚
ã“ã“ã‹ã‚‰ã¯ã€Œå£Šã•ãšã«ä¸€æ®µãƒ¬ãƒ™ãƒ«ã‚’ä¸Šã’ã‚‹ã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã«å…¥ã‚Œã¾ã™ã€‚

ä»¥ä¸‹ã¯ **æœ€å°å¤‰æ›´ã§è¨­è¨ˆã‚’ä¸€æ®µå¼•ãä¸Šã’ã‚‹å…·ä½“æ¡ˆ**ã§ã™ã€‚

---

# ğŸ¯ ç¾çŠ¶ã‚³ãƒ¼ãƒ‰ã®èª²é¡Œï¼ˆé‡è¦ãªé †ï¼‰

### 1ï¸âƒ£ ä¾å­˜ãŒãƒãƒ¼ãƒ‰å†…ã«åŸ‹ã‚è¾¼ã¾ã‚Œã¦ã„ã‚‹

```python
vectorstore = get_vectorstore()
reranker = get_reranker()
llm = get_llm()
```

â†’ ãƒ†ã‚¹ãƒˆãƒ»å·®ã—æ›¿ãˆãŒé›£ã—ã„

---

### 2ï¸âƒ£ TypedDictã®ã¾ã¾ãªã®ã§å‹å®‰å…¨æ€§ãŒå¼±ã„

* `state["documents"]` ã®å­˜åœ¨ä¿è¨¼ãŒå¼±ã„
* IDEè£œå®ŒãŒå¼±ã„
* ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æã§å£Šã‚Œã‚„ã™ã„

---

### 3ï¸âƒ£ promptçµ„ã¿ç«‹ã¦ãŒãƒãƒ¼ãƒ‰ã«ãƒ™ã‚¿æ›¸ã

å°†æ¥ï¼š

* å¼•ç”¨ä»˜ãå›ç­”
* sourceåŸ‹ã‚è¾¼ã¿
* ä¸è¶³æ™‚ã®ã‚¬ãƒ¼ãƒ‰
* JSONå‡ºåŠ›

ã‚’ã‚„ã‚‹ã¨ generate_node ãŒè‚¥å¤§åŒ–ã—ã¾ã™ã€‚

---

### 4ï¸âƒ£ ask.py ã® search ã¨ graph å†… retrieve ãŒäºŒé‡å®Ÿè£…

ä»Šã¯ï¼š

* ask.py ã« search()
* graph.py ã« retrieve()

åŒã˜å‡¦ç†ãŒäºŒç®‡æ‰€ã«ã‚ã‚Šã¾ã™ã€‚
å°†æ¥å¿…ãšã‚ºãƒ¬ã¾ã™ã€‚

---

# ğŸ”§ æ¨å¥¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ï¼ˆå®‰å…¨ãƒ»æ®µéšçš„ï¼‰

---

# âœ… STEP 1ï¼šRAGState ã‚’ dataclass ã«å¤‰æ›´ï¼ˆæœ€å„ªå…ˆï¼‰

### å¤‰æ›´å‰

```python
class RAGState(TypedDict):
```

### å¤‰æ›´å¾Œ

```python
from dataclasses import dataclass, field
from typing import List
from langchain_core.documents import Document

@dataclass
class RAGState:
    query: str
    documents: List[Document] = field(default_factory=list)
    reranked_documents: List[Document] = field(default_factory=list)
    contexts: List[str] = field(default_factory=list)
    prompt: str = ""
    answer: str = ""
    sources: List[str] = field(default_factory=list)
```

---

### ãƒãƒ¼ãƒ‰ã‚‚ dict ã§ã¯ãªã state ã‚’è¿”ã™å½¢ã¸

ä¾‹ï¼š

```python
def retrieve(state: RAGState) -> RAGState:
    vectorstore = get_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": SEARCH_K})
    state.documents = retriever.invoke(state.query)
    return state
```

LangGraph ã¯ dataclass ã§ã‚‚å‹•ãã¾ã™ã€‚

---

# âœ… STEP 2ï¼šprompt ã‚’åˆ†é›¢

æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ï¼š

```python
# app/prompting.py

def build_prompt(query: str, contexts: list[str]) -> str:
    joined = "\n\n".join(contexts)
    return f"""ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«å›ç­”ã—ã¦ãã ã•ã„:

{joined}

è³ªå•:{query}
å›ç­”:"""
```

generate_node ã¯ã“ã†ãªã‚Šã¾ã™ï¼š

```python
from app.prompting import build_prompt

def generate_node(state: RAGState) -> RAGState:
    state.contexts = [doc.page_content for doc in state.reranked_documents]
    state.sources = [doc.metadata.get("source", "") for doc in state.reranked_documents]

    state.prompt = build_prompt(state.query, state.contexts)

    llm = get_llm()
    state.answer = llm.invoke(state.prompt)

    return state
```

---

ã“ã‚Œã§ï¼š

* ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹è‰¯ãŒå®‰å…¨ã«ã§ãã‚‹
* JSONå‡ºåŠ›ã‚‚ç°¡å˜ã«ã§ãã‚‹
* å›ç­”ãƒ«ãƒ¼ãƒ«ã®é«˜åº¦åŒ–ãŒå¯èƒ½

---

# âœ… STEP 3ï¼šsearch() ã‚’ graph å´ã«çµ±åˆ

ask.py ã® search() ã¯å‰Šé™¤æ¨å¥¨ã§ã™ã€‚

ç†ç”±ï¼š

* retrieve ãƒãƒ¼ãƒ‰ãŒæ—¢ã«åŒã˜å‡¦ç†ã‚’ã—ã¦ã„ã‚‹
* äºŒé‡ç®¡ç†ã¯äº‹æ•…ã®å…ƒ

ask.py ã¯ã“ã†ã™ã‚‹ã®ãŒç†æƒ³ï¼š

```python
def main():
    query = sys.argv[1]

    from app.graph import get_graph
    graph = get_graph()

    state = RAGState(query=query)
    result = graph.invoke(state)

    print("\n=== Answer ===\n")
    print(result.answer)
    print("\n=== Sources ===\n")
    for source in result.sources:
        print(f"- {source}")
```

---

# âœ… STEP 4ï¼šä¾å­˜æ³¨å…¥ï¼ˆä¸Šç´šæ”¹å–„ï¼‰

ç¾çŠ¶ï¼š

```
retrieve() ãŒå†…éƒ¨ã§ get_vectorstore() å‘¼ã¶
```

ç†æƒ³ï¼š

```
graph ã‚’ build ã™ã‚‹ã¨ãã«ä¾å­˜ã‚’æ¸¡ã™
```

ä¾‹ï¼š

```python
def build_rag_graph(vectorstore, reranker, llm):
```

ã§ã‚‚ã“ã‚Œã¯ä»Šã™ãã‚„ã‚‰ãªãã¦å¤§ä¸ˆå¤«ã§ã™ã€‚

ã¾ãšã¯ dataclass åŒ–ãŒæœ€é‡è¦ã§ã™ã€‚

---

# ğŸ“ˆ ã“ã®å¤‰æ›´ã§å¾—ã‚‰ã‚Œã‚‹ãƒ¡ãƒªãƒƒãƒˆ

| æ”¹å–„         | åŠ¹æœ             |
| ---------- | -------------- |
| dataclassåŒ– | IDEè£œå®Œãƒ»å‹å®‰å…¨ãƒ»äº‹æ•…é˜²æ­¢ |
| promptåˆ†é›¢   | å›ç­”å“è³ªæ”¹å–„ãŒå®¹æ˜“      |
| searchå‰Šé™¤   | ãƒ­ã‚¸ãƒƒã‚¯ä¸€å…ƒåŒ–        |
| stateç›´æ¥æ›´æ–°  | dictã‚­ãƒ¼èª¤ã‚Šæ¶ˆæ»…     |

---

# ğŸ§  æ¬¡ã®ãƒ¬ãƒ™ãƒ«ï¼ˆå°†æ¥ï¼‰

ã‚‚ã—å°†æ¥ã‚„ã‚‹ãªã‚‰ï¼š

* RAGState ã‚’ pydantic ã«
* Container å°å…¥
* Retrieval ã¨ Rerank ã‚’åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸
* Streaming å¯¾å¿œ
* Structured output å¯¾å¿œ

---

# ğŸ ä»Šã‚„ã‚‹ã¹ãå„ªå…ˆé †ä½

1. RAGState ã‚’ dataclass ã«å¤‰æ›´
2. generate ã® prompt åˆ†é›¢
3. ask.search å‰Šé™¤

ã“ã‚Œã ã‘ã§ã‚³ãƒ¼ãƒ‰å“è³ªãŒä¸€æ®µä¸ŠãŒã‚Šã¾ã™ã€‚

---

å¤§å¤‰ã‚ˆãæ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚
ã“ã“ã‹ã‚‰ã¯ã€Œå£Šã•ãšã«ä¸€æ®µãƒ¬ãƒ™ãƒ«ã‚’ä¸Šã’ã‚‹ã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã«å…¥ã‚Œã¾ã™ã€‚

ä»¥ä¸‹ã¯ æœ€å°å¤‰æ›´ã§è¨­è¨ˆã‚’ä¸€æ®µå¼•ãä¸Šã’ã‚‹å…·ä½“æ¡ˆã§ã™ã€‚

ğŸ¯ ç¾çŠ¶ã‚³ãƒ¼ãƒ‰ã®èª²é¡Œï¼ˆé‡è¦ãªé †ï¼‰
1ï¸âƒ£ ä¾å­˜ãŒãƒãƒ¼ãƒ‰å†…ã«åŸ‹ã‚è¾¼ã¾ã‚Œã¦ã„ã‚‹
vectorstore = get_vectorstore()
reranker = get_reranker()
llm = get_llm()

â†’ ãƒ†ã‚¹ãƒˆãƒ»å·®ã—æ›¿ãˆãŒé›£ã—ã„

2ï¸âƒ£ TypedDictã®ã¾ã¾ãªã®ã§å‹å®‰å…¨æ€§ãŒå¼±ã„

state["documents"] ã®å­˜åœ¨ä¿è¨¼ãŒå¼±ã„

IDEè£œå®ŒãŒå¼±ã„

ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æã§å£Šã‚Œã‚„ã™ã„

3ï¸âƒ£ promptçµ„ã¿ç«‹ã¦ãŒãƒãƒ¼ãƒ‰ã«ãƒ™ã‚¿æ›¸ã

å°†æ¥ï¼š

å¼•ç”¨ä»˜ãå›ç­”

sourceåŸ‹ã‚è¾¼ã¿

ä¸è¶³æ™‚ã®ã‚¬ãƒ¼ãƒ‰

JSONå‡ºåŠ›

ã‚’ã‚„ã‚‹ã¨ generate_node ãŒè‚¥å¤§åŒ–ã—ã¾ã™ã€‚

4ï¸âƒ£ ask.py ã® search ã¨ graph å†… retrieve ãŒäºŒé‡å®Ÿè£…

ä»Šã¯ï¼š

ask.py ã« search()

graph.py ã« retrieve()

åŒã˜å‡¦ç†ãŒäºŒç®‡æ‰€ã«ã‚ã‚Šã¾ã™ã€‚
å°†æ¥å¿…ãšã‚ºãƒ¬ã¾ã™ã€‚

ğŸ”§ æ¨å¥¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ï¼ˆå®‰å…¨ãƒ»æ®µéšçš„ï¼‰
âœ… STEP 1ï¼šRAGState ã‚’ dataclass ã«å¤‰æ›´ï¼ˆæœ€å„ªå…ˆï¼‰
å¤‰æ›´å‰
class RAGState(TypedDict):
å¤‰æ›´å¾Œ
from dataclasses import dataclass, field
from typing import List
from langchain_core.documents import Document

@dataclass
class RAGState:
    query: str
    documents: List[Document] = field(default_factory=list)
    reranked_documents: List[Document] = field(default_factory=list)
    contexts: List[str] = field(default_factory=list)
    prompt: str = ""
    answer: str = ""
    sources: List[str] = field(default_factory=list)
ãƒãƒ¼ãƒ‰ã‚‚ dict ã§ã¯ãªã state ã‚’è¿”ã™å½¢ã¸

ä¾‹ï¼š

def retrieve(state: RAGState) -> RAGState:
    vectorstore = get_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": SEARCH_K})
    state.documents = retriever.invoke(state.query)
    return state

LangGraph ã¯ dataclass ã§ã‚‚å‹•ãã¾ã™ã€‚

âœ… STEP 2ï¼šprompt ã‚’åˆ†é›¢

æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ï¼š

# app/prompting.py

def build_prompt(query: str, contexts: list[str]) -> str:
    joined = "\n\n".join(contexts)
    return f"""ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«å›ç­”ã—ã¦ãã ã•ã„:

{joined}

è³ªå•:{query}
å›ç­”:"""

generate_node ã¯ã“ã†ãªã‚Šã¾ã™ï¼š

from app.prompting import build_prompt

def generate_node(state: RAGState) -> RAGState:
    state.contexts = [doc.page_content for doc in state.reranked_documents]
    state.sources = [doc.metadata.get("source", "") for doc in state.reranked_documents]

    state.prompt = build_prompt(state.query, state.contexts)

    llm = get_llm()
    state.answer = llm.invoke(state.prompt)

    return state

ã“ã‚Œã§ï¼š

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹è‰¯ãŒå®‰å…¨ã«ã§ãã‚‹

JSONå‡ºåŠ›ã‚‚ç°¡å˜ã«ã§ãã‚‹

å›ç­”ãƒ«ãƒ¼ãƒ«ã®é«˜åº¦åŒ–ãŒå¯èƒ½

âœ… STEP 3ï¼šsearch() ã‚’ graph å´ã«çµ±åˆ

ask.py ã® search() ã¯å‰Šé™¤æ¨å¥¨ã§ã™ã€‚

ç†ç”±ï¼š

retrieve ãƒãƒ¼ãƒ‰ãŒæ—¢ã«åŒã˜å‡¦ç†ã‚’ã—ã¦ã„ã‚‹

äºŒé‡ç®¡ç†ã¯äº‹æ•…ã®å…ƒ

ask.py ã¯ã“ã†ã™ã‚‹ã®ãŒç†æƒ³ï¼š

def main():
    query = sys.argv[1]

    from app.graph import get_graph
    graph = get_graph()

    state = RAGState(query=query)
    result = graph.invoke(state)

    print("\n=== Answer ===\n")
    print(result.answer)
    print("\n=== Sources ===\n")
    for source in result.sources:
        print(f"- {source}")
âœ… STEP 4ï¼šä¾å­˜æ³¨å…¥ï¼ˆä¸Šç´šæ”¹å–„ï¼‰

ç¾çŠ¶ï¼š

retrieve() ãŒå†…éƒ¨ã§ get_vectorstore() å‘¼ã¶

ç†æƒ³ï¼š

graph ã‚’ build ã™ã‚‹ã¨ãã«ä¾å­˜ã‚’æ¸¡ã™

ä¾‹ï¼š

def build_rag_graph(vectorstore, reranker, llm):

ã§ã‚‚ã“ã‚Œã¯ä»Šã™ãã‚„ã‚‰ãªãã¦å¤§ä¸ˆå¤«ã§ã™ã€‚

ã¾ãšã¯ dataclass åŒ–ãŒæœ€é‡è¦ã§ã™ã€‚

ğŸ“ˆ ã“ã®å¤‰æ›´ã§å¾—ã‚‰ã‚Œã‚‹ãƒ¡ãƒªãƒƒãƒˆ
æ”¹å–„	åŠ¹æœ
dataclassåŒ–	IDEè£œå®Œãƒ»å‹å®‰å…¨ãƒ»äº‹æ•…é˜²æ­¢
promptåˆ†é›¢	å›ç­”å“è³ªæ”¹å–„ãŒå®¹æ˜“
searchå‰Šé™¤	ãƒ­ã‚¸ãƒƒã‚¯ä¸€å…ƒåŒ–
stateç›´æ¥æ›´æ–°	dictã‚­ãƒ¼èª¤ã‚Šæ¶ˆæ»…
ğŸ§  æ¬¡ã®ãƒ¬ãƒ™ãƒ«ï¼ˆå°†æ¥ï¼‰

ã‚‚ã—å°†æ¥ã‚„ã‚‹ãªã‚‰ï¼š

RAGState ã‚’ pydantic ã«

Container å°å…¥

Retrieval ã¨ Rerank ã‚’åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸

Streaming å¯¾å¿œ

Structured output å¯¾å¿œ

ğŸ ä»Šã‚„ã‚‹ã¹ãå„ªå…ˆé †ä½

RAGState ã‚’ dataclass ã«å¤‰æ›´

generate ã® prompt åˆ†é›¢

ask.search å‰Šé™¤

ã“ã‚Œã ã‘ã§ã‚³ãƒ¼ãƒ‰å“è³ªãŒä¸€æ®µä¸ŠãŒã‚Šã¾ã™ã€‚

ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€
æ¬¡ã¯ã€Œå®Œå…¨ã«ç¶ºéº—ã«ã—ãŸæœ€çµ‚å½¢ã® graph.py å…¨ä½“ã‚³ãƒ¼ãƒ‰ã€ã‚’æç¤ºã—ã¾ã™ã‹ï¼Ÿ

ã‹ãªã‚Šæ´—ç·´ã•ã‚ŒãŸå½¢ã¾ã§æŒã£ã¦ã„ã‘ã¾ã™ã€‚

ä¾é ¼

graph.py å…¨ä½“ã‚³ãƒ¼ãƒ‰

æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚
dataclassåŒ– + promptåˆ†é›¢ + çŠ¶æ…‹ç›´æ¥æ›´æ–° + å¯èª­æ€§å‘ä¸Šã¾ã§åæ˜ ã—ãŸã€æ•´ç†æ¸ˆã¿ã® graph.py å®Œå…¨ç‰ˆã‚’æç¤ºã„ãŸã—ã¾ã™ã€‚

âœ… æ”¹è‰¯ç‰ˆ app/graph.pyï¼ˆå®Œæˆå½¢ï¼‰
from dataclasses import dataclass, field
from typing import List
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END

from app.db import get_vectorstore
from app.llm import get_llm
from app.reranker import get_reranker
from app.config import SEARCH_K, RERANK_TOP_K
from app.prompting import build_prompt


# =========================
# RAG State
# =========================

@dataclass
class RAGState:
    query: str
    documents: List[Document] = field(default_factory=list)
    reranked_documents: List[Document] = field(default_factory=list)
    contexts: List[str] = field(default_factory=list)
    prompt: str = ""
    answer: str = ""
    sources: List[str] = field(default_factory=list)


# =========================
# Nodes
# =========================

def retrieve(state: RAGState) -> RAGState:
    """
    pgvector ã‹ã‚‰ SEARCH_K ä»¶ã‚’å–å¾—
    """
    vectorstore = get_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": SEARCH_K})
    state.documents = retriever.invoke(state.query)
    return state


def rerank_node(state: RAGState) -> RAGState:
    """
    Cross-Encoder ã«ã‚ˆã‚‹ Re-ranking
    """
    if not state.documents:
        return state

    reranker = get_reranker()
    reranked = reranker.compress_documents(state.documents, state.query)

    # å¿µã®ãŸã‚ list åŒ–
    state.reranked_documents = list(reranked[:RERANK_TOP_K])
    return state


def generate_node(state: RAGState) -> RAGState:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ç«‹ â†’ LLMç”Ÿæˆ
    """
    if not state.reranked_documents:
        state.answer = "é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        return state

    state.contexts = [doc.page_content for doc in state.reranked_documents]
    state.sources = [
        doc.metadata.get("source", "") for doc in state.reranked_documents
    ]

    state.prompt = build_prompt(state.query, state.contexts)

    llm = get_llm()
    state.answer = llm.invoke(state.prompt)

    return state


# =========================
# Graph Builder
# =========================

def build_rag_graph():
    workflow = StateGraph(RAGState)

    workflow.add_node("retrieve", retrieve)
    workflow.add_node("rerank", rerank_node)
    workflow.add_node("generate", generate_node)

    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "rerank")
    workflow.add_edge("rerank", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()


# =========================
# Singleton Graph
# =========================

_graph = None


def get_graph():
    global _graph
    if _graph is None:
        _graph = build_rag_graph()
    return _graph
âœ… ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§æ”¹å–„ã•ã‚ŒãŸç‚¹
âœ” dataclassæ¡ç”¨

å‹è£œå®ŒãŒå¼·åŒ–

ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æäº‹æ•…ãŒæ¶ˆæ»…

IDEãŒéå¸¸ã«æ‰±ã„ã‚„ã™ã„

âœ” dictæ“ä½œå®Œå…¨æ’é™¤

ä»¥å‰ï¼š

return {"documents": docs}

ç¾åœ¨ï¼š

state.documents = docs
return state

ã‚­ãƒ¼ã‚¿ã‚¤ãƒ—ãƒŸã‚¹äº‹æ•…ã‚¼ãƒ­ã€‚

âœ” ç©ºæ¤œç´¢æ™‚ã®å®‰å…¨ã‚¬ãƒ¼ãƒ‰è¿½åŠ 
if not state.reranked_documents:
    state.answer = "é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã‚‚å£Šã‚Œã¾ã›ã‚“ã€‚

âœ” Promptãƒ­ã‚¸ãƒƒã‚¯åˆ†é›¢

build_prompt() ã«å§”è­²æ¸ˆã¿ã€‚

ä»Šå¾Œï¼š

JSONå‡ºåŠ›

å¼•ç”¨å½¢å¼

Markdownæ•´å½¢

æŒ‡ç¤ºå¼·åŒ–

ãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚

ğŸš€ æ¬¡ã«ã‚„ã‚‹ã¨è‰¯ã„æ”¹è‰¯ï¼ˆä»»æ„ï¼‰

sources ã‚’é‡è¤‡æ’é™¤ï¼ˆset â†’ listï¼‰

Containerå°å…¥ï¼ˆä¾å­˜æ³¨å…¥ï¼‰

Retrievalã‚’åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸

ãƒ­ã‚°è¿½åŠ ï¼ˆdebugç”¨ï¼‰

streamingå¯¾å¿œ

ğŸ çŠ¶æ…‹

ã“ã®å½¢ã¯ï¼š

CLIå‹

CPUå°‚ç”¨

pgvector

Cross-Encoder

LangGraph

ã®æ§‹æˆã¨ã—ã¦ã‹ãªã‚Šç¶ºéº—ã§ã™ã€‚

ã‚‚ã—ã”å¸Œæœ›ã§ã—ãŸã‚‰ã€
æ¬¡ã¯ ä¾å­˜æ³¨å…¥ç‰ˆï¼ˆæœ¬æ ¼DIæ§‹é€ ï¼‰graph.py ã‚’æç¤ºã§ãã¾ã™ã€‚

ã‹ãªã‚Šæ´—ç·´ã•ã‚ŒãŸè¨­è¨ˆã«æŒã£ã¦ã„ãã¾ã™ãŒã€é€²ã‚ã¾ã™ã‹ï¼Ÿ

ä¾é ¼ ã“ã‚ŒãŒé‡è¦
ä¾å­˜æ³¨å…¥ç‰ˆï¼ˆæœ¬æ ¼DIæ§‹é€ ï¼‰graph.py

æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚
ä»Šå›ã¯ ã€Œæœ¬æ ¼DIï¼ˆä¾å­˜æ³¨å…¥ï¼‰æ§‹é€ ã€ç‰ˆ graph.py ã‚’æç¤ºã—ã¾ã™ã€‚

ç›®çš„ã¯ï¼š

ãƒãƒ¼ãƒ‰å†…ã‹ã‚‰ get_llm() ç­‰ã‚’æ’é™¤

ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¾å­˜ã‚¼ãƒ­

ãƒ†ã‚¹ãƒˆæ™‚ã«å®Œå…¨ãƒ¢ãƒƒã‚¯å·®ã—æ›¿ãˆå¯èƒ½

LangGraph ã¯ç¶­æŒ

ğŸ¯ è¨­è¨ˆæ–¹é‡

ä¾å­˜ã‚’ã€Œå¤–ã‹ã‚‰æ¸¡ã™ã€å½¢ã«ã—ã¾ã™ã€‚

æ³¨å…¥å¯¾è±¡ï¼š

vectorstore

reranker

llm

prompt_builder

graphæ§‹ç¯‰æ™‚ã«ã™ã¹ã¦æ¸¡ã—ã¾ã™ã€‚

âœ… DIç‰ˆ graph.pyï¼ˆå®Œæˆå½¢ï¼‰
from dataclasses import dataclass, field
from typing import List, Callable
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END


# =========================
# RAG State
# =========================

@dataclass
class RAGState:
    query: str
    documents: List[Document] = field(default_factory=list)
    reranked_documents: List[Document] = field(default_factory=list)
    contexts: List[str] = field(default_factory=list)
    prompt: str = ""
    answer: str = ""
    sources: List[str] = field(default_factory=list)


# =========================
# Graph Builder (DI)
# =========================

def build_rag_graph(
    *,
    vectorstore,
    reranker,
    llm,
    prompt_builder: Callable[[str, List[str]], str],
    search_k: int,
    rerank_top_k: int,
):
    """
    å®Œå…¨ä¾å­˜æ³¨å…¥å‹ RAG Graph

    Parameters
    ----------
    vectorstore : PGVector ãªã©
    reranker : CrossEncoderReranker ãªã©
    llm : LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    prompt_builder : (query, contexts) -> str
    search_k : æ¤œç´¢ä»¶æ•°
    rerank_top_k : å†é †ä½ä»˜ã‘ä»¶æ•°
    """

    # -------------------------
    # Nodes
    # -------------------------

    def retrieve(state: RAGState) -> RAGState:
        retriever = vectorstore.as_retriever(
            search_kwargs={"k": search_k}
        )
        state.documents = retriever.invoke(state.query)
        return state

    def rerank_node(state: RAGState) -> RAGState:
        if not state.documents:
            return state

        reranked = reranker.compress_documents(
            state.documents, state.query
        )

        state.reranked_documents = list(reranked[:rerank_top_k])
        return state

    def generate_node(state: RAGState) -> RAGState:
        if not state.reranked_documents:
            state.answer = "é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            return state

        state.contexts = [
            doc.page_content for doc in state.reranked_documents
        ]

        state.sources = list({
            doc.metadata.get("source", "")
            for doc in state.reranked_documents
        })

        state.prompt = prompt_builder(
            state.query,
            state.contexts,
        )

        state.answer = llm.invoke(state.prompt)

        return state

    # -------------------------
    # Graphæ§‹ç¯‰
    # -------------------------

    workflow = StateGraph(RAGState)

    workflow.add_node("retrieve", retrieve)
    workflow.add_node("rerank", rerank_node)
    workflow.add_node("generate", generate_node)

    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "rerank")
    workflow.add_edge("rerank", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()
âœ… ã“ã‚Œã§ä½•ãŒå¤‰ã‚ã‚‹ã‹
âŒ æ—§æ§‹é€ 

ãƒãƒ¼ãƒ‰å†…éƒ¨ã§ï¼š

get_vectorstore()
get_llm()
get_reranker()

ä¾å­˜ãŒå›ºå®šåŒ– â†’ ãƒ†ã‚¹ãƒˆå›°é›£

âœ… æ–°æ§‹é€ 
graph = build_rag_graph(
    vectorstore=real_vectorstore,
    reranker=real_reranker,
    llm=real_llm,
    prompt_builder=build_prompt,
    search_k=10,
    rerank_top_k=3,
)

å®Œå…¨å¤–éƒ¨æ³¨å…¥ã€‚

ğŸ§ª ãƒ†ã‚¹ãƒˆãŒåŠ‡çš„ã«æ¥½ã«ãªã‚‹

ä¾‹ï¼š

fake_llm = MagicMock()
fake_llm.invoke.return_value = "mock answer"

graph = build_rag_graph(
    vectorstore=fake_vectorstore,
    reranker=fake_reranker,
    llm=fake_llm,
    prompt_builder=lambda q, c: "mock prompt",
    search_k=5,
    rerank_top_k=2,
)

â†’ DBã‚‚ãƒ¢ãƒ‡ãƒ«ã‚‚ä¸è¦

ğŸ“¦ get_graph() å´ã¯ã“ã†ãªã‚‹

åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã§ï¼š

from app.db import get_vectorstore
from app.llm import get_llm
from app.reranker import get_reranker
from app.prompting import build_prompt
from app.config import SEARCH_K, RERANK_TOP_K

_graph = None

def get_graph():
    global _graph
    if _graph is None:
        _graph = build_rag_graph(
            vectorstore=get_vectorstore(),
            reranker=get_reranker(),
            llm=get_llm(),
            prompt_builder=build_prompt,
            search_k=SEARCH_K,
            rerank_top_k=RERANK_TOP_K,
        )
    return _graph
ğŸ— ã“ã®æ§‹é€ ã®ãƒ¬ãƒ™ãƒ«

ã“ã‚Œã¯å®Ÿè³ªï¼š

Clean Architectureå¯„ã‚Š

DDDå¯„ã‚Š

ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºRAGæ§‹é€ 

LangChainä¾å­˜ã‚’é–‰ã˜è¾¼ã‚ãŸæ§‹é€ 

ã«ãªã£ã¦ã„ã¾ã™ã€‚

ğŸ§  æ¬¡ã®é€²åŒ–ï¼ˆä¸Šç´šï¼‰

ã“ã®å…ˆã¯ï¼š

Containerã‚¯ãƒ©ã‚¹åŒ–ï¼ˆä¾å­˜é›†ç´„ï¼‰

RetrievalStrategyãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–

Streamingãƒãƒ¼ãƒ‰è¿½åŠ 

StructuredOutputå¯¾å¿œ

AsyncGraphå¯¾å¿œ

ã¾ã§æŒã£ã¦ã„ã‘ã¾ã™ã€‚

ğŸ”¥ çµè«–

ã“ã®DIç‰ˆã¯ï¼š

âœ” æœ¬ç•ªé‹ç”¨è€æ€§ã‚ã‚Š
âœ” ãƒ†ã‚¹ãƒˆå®¹æ˜“
âœ” å·®ã—æ›¿ãˆè‡ªç”±
âœ” å°†æ¥æ‹¡å¼µæ€§ã‚ã‚Š

CLIå‹RAGã¨ã—ã¦éå¸¸ã«å¥å…¨ãªæ§‹é€ ã§ã™ã€‚

æ¬¡ã¯ï¼š

ã€ŒContainerå°å…¥ç‰ˆï¼ˆã•ã‚‰ã«æ´—ç·´ï¼‰ã€
ã€ŒRetrievalStrategyåˆ†é›¢ç‰ˆã€
ã€ŒStreamingå¯¾å¿œç‰ˆã€

ã©ã“ã¾ã§é€²ã‚ã¾ã™ã‹ï¼Ÿ

ä¾é ¼
ã€ŒContainerå°å…¥ç‰ˆï¼ˆã•ã‚‰ã«æ´—ç·´ï¼‰ã€

æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚**Containerå°å…¥ç‰ˆï¼ˆã•ã‚‰ã«æ´—ç·´ï¼‰**ã¨ã—ã¦ã€ä»¥ä¸‹ã®3ç‚¹ã‚’æƒãˆã‚‹ã®ãŒä¸€ç•ªãã‚Œã„ã§ã™ã€‚

app/container.pyï¼šä¾å­˜ã®ç”Ÿæˆãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ=ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®é›†ç´„ï¼‰

app/graph.pyï¼šDIå‰æã® build_rag_graph(container=...) ã¨ get_graph()

ï¼ˆä»»æ„ï¼‰app/protocols.pyï¼šå‹ï¼ˆProtocolï¼‰ã§å¢ƒç•Œã‚’å›ºã‚ã‚‹ï¼ˆãªãã¦ã‚‚OKï¼‰

ã“ã“ã§ã¯ ã€Œãã®ã¾ã¾ã‚³ãƒ”ãƒšã§å‹•ãã€æœ€å°ã‚»ãƒƒãƒˆã‚’æç¤ºã—ã¾ã™ï¼ˆProtocolã¯ä»»æ„ãªã®ã§çœç•¥ï¼‰ã€‚

1) app/container.pyï¼ˆæ–°è¦ï¼‰
from __future__ import annotations

from dataclasses import dataclass
from typing import Callable, Optional, List

from app.config import SEARCH_K, RERANK_TOP_K
from app.db import get_vectorstore
from app.llm import get_llm
from app.reranker import get_reranker
from app.prompting import build_prompt


@dataclass(frozen=True)
class RagSettings:
    search_k: int = SEARCH_K
    rerank_top_k: int = RERANK_TOP_K


class AppContainer:
    """
    ä¾å­˜ï¼ˆDB/ãƒ¢ãƒ‡ãƒ«/è¨­å®š/é–¢æ•°ï¼‰ã‚’é›†ç´„ã—ã€é…å»¶åˆæœŸåŒ– & ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠã€‚
    ãƒ†ã‚¹ãƒˆã§ã¯ AppContainer ã‚’å·®ã—æ›¿ãˆã‚‹ã ã‘ã§å…¨ä¾å­˜ã‚’å…¥ã‚Œæ›¿ãˆå¯èƒ½ã€‚
    """

    def __init__(
        self,
        *,
        settings: RagSettings | None = None,
        vectorstore=None,
        reranker=None,
        llm=None,
        prompt_builder: Callable[[str, List[str]], str] | None = None,
    ):
        self.settings = settings or RagSettings()

        # æ˜ç¤ºæ³¨å…¥ã•ã‚ŒãŸä¾å­˜ï¼ˆãƒ†ã‚¹ãƒˆã§ä¾¿åˆ©ï¼‰
        self._vectorstore = vectorstore
        self._reranker = reranker
        self._llm = llm
        self._prompt_builder = prompt_builder

    # --- Providers (lazy) ---

    @property
    def vectorstore(self):
        if self._vectorstore is None:
            self._vectorstore = get_vectorstore()
        return self._vectorstore

    @property
    def reranker(self):
        if self._reranker is None:
            self._reranker = get_reranker()
        return self._reranker

    @property
    def llm(self):
        if self._llm is None:
            self._llm = get_llm()
        return self._llm

    @property
    def prompt_builder(self) -> Callable[[str, List[str]], str]:
        if self._prompt_builder is None:
            self._prompt_builder = build_prompt
        return self._prompt_builder

ãƒã‚¤ãƒ³ãƒˆï¼š

ã‚³ãƒ³ãƒ†ãƒŠãŒã€Œã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®æ•£åœ¨ã€ã‚’å¸åã—ã¾ã™ï¼ˆget_llm()ç­‰ã¯ã“ã“ã ã‘ï¼‰

ãƒ†ã‚¹ãƒˆæ™‚ã¯ AppContainer(llm=fake_llm, vectorstore=fake_vs, ...) ã§å·®ã—æ›¿ãˆå¯èƒ½

RagSettings ã§ SEARCH_K ç­‰ã®è¨­å®šã‚‚ã¾ã¨ã‚ã¦æ¸¡ã›ã¾ã™

2) app/graph.pyï¼ˆContainerå°å…¥ç‰ˆï¼šç½®ãæ›ãˆï¼‰
from __future__ import annotations

from dataclasses import dataclass, field
from typing import List
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END

from app.container import AppContainer, RagSettings


# =========================
# RAG State
# =========================

@dataclass
class RAGState:
    query: str
    documents: List[Document] = field(default_factory=list)
    reranked_documents: List[Document] = field(default_factory=list)
    contexts: List[str] = field(default_factory=list)
    prompt: str = ""
    answer: str = ""
    sources: List[str] = field(default_factory=list)


# =========================
# Graph Builder (Container DI)
# =========================

def build_rag_graph(*, container: AppContainer):
    """
    Container ã‹ã‚‰ä¾å­˜ã‚’å–å¾—ã—ã¦ãƒãƒ¼ãƒ‰ã¸é–‰ã˜è¾¼ã‚ã‚‹ã€‚
    ãƒãƒ¼ãƒ‰ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ã§ã¯ãªãã€container ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£ã§æ§‹æˆã€‚
    """

    search_k = container.settings.search_k
    rerank_top_k = container.settings.rerank_top_k

    def retrieve(state: RAGState) -> RAGState:
        retriever = container.vectorstore.as_retriever(search_kwargs={"k": search_k})
        state.documents = retriever.invoke(state.query)
        return state

    def rerank_node(state: RAGState) -> RAGState:
        if not state.documents:
            return state
        reranked = container.reranker.compress_documents(state.documents, state.query)
        state.reranked_documents = list(reranked[:rerank_top_k])
        return state

    def generate_node(state: RAGState) -> RAGState:
        if not state.reranked_documents:
            state.answer = "é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            state.sources = []
            state.contexts = []
            state.prompt = ""
            return state

        state.contexts = [doc.page_content for doc in state.reranked_documents]

        # é‡è¤‡æ’é™¤ã—ã¤ã¤ã€ç©ºæ–‡å­—ã¯è½ã¨ã™
        sources = []
        seen = set()
        for doc in state.reranked_documents:
            s = (doc.metadata or {}).get("source", "") or ""
            if s and s not in seen:
                seen.add(s)
                sources.append(s)
        state.sources = sources

        state.prompt = container.prompt_builder(state.query, state.contexts)
        state.answer = container.llm.invoke(state.prompt)
        return state

    workflow = StateGraph(RAGState)
    workflow.add_node("retrieve", retrieve)
    workflow.add_node("rerank", rerank_node)
    workflow.add_node("generate", generate_node)

    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "rerank")
    workflow.add_edge("rerank", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()


# =========================
# Singleton: graph + container
# =========================

_graph = None
_container = None


def get_container() -> AppContainer:
    """
    æœ¬ç•ªç”¨ã‚³ãƒ³ãƒ†ãƒŠï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰ã€‚
    ãƒ†ã‚¹ãƒˆã§ã¯ã“ã®é–¢æ•°ã‚’ãƒ¢ãƒƒã‚¯ã™ã‚‹ã‹ã€get_graph(container=...) ã‚’ä½¿ã†ã€‚
    """
    global _container
    if _container is None:
        _container = AppContainer(settings=RagSettings())
    return _container


def get_graph(*, container: AppContainer | None = None):
    """
    ã‚³ãƒ³ãƒ†ãƒŠå·®ã—æ›¿ãˆå¯èƒ½ãª get_graphã€‚
    - æœ¬ç•ª: get_graph()
    - ãƒ†ã‚¹ãƒˆ: get_graph(container=fake_container)
    """
    global _graph
    if container is not None:
        # ãƒ†ã‚¹ãƒˆ/æ¤œè¨¼ç”¨ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ã‚ãšã€ãã®containerå°‚ç”¨ã‚°ãƒ©ãƒ•ã‚’è¿”ã™
        return build_rag_graph(container=container)

    if _graph is None:
        _graph = build_rag_graph(container=get_container())
    return _graph

ãƒã‚¤ãƒ³ãƒˆï¼š

ãƒãƒ¼ãƒ‰å†…ã« get_llm() ãªã©ã¯ ä¸€åˆ‡å‡ºã¦ã“ãªã„

ä¾å­˜ã®å…¥å£ã¯ containerã ã‘

get_graph(container=...) ã«ã‚ˆã‚Š ãƒ†ã‚¹ãƒˆæ™‚ã®å·®ã—æ›¿ãˆãŒç°¡å˜

3) ãƒ†ã‚¹ãƒˆã§ã®ä½¿ã„æ–¹ï¼ˆä¾‹ï¼‰
from unittest.mock import MagicMock
from app.container import AppContainer, RagSettings
from app.graph import get_graph, RAGState

fake_vs = MagicMock()
fake_retriever = MagicMock()
fake_vs.as_retriever.return_value = fake_retriever
fake_retriever.invoke.return_value = []  # ä½•ã‚‚ãƒ’ãƒƒãƒˆã—ãªã„æƒ³å®š

fake_reranker = MagicMock()
fake_llm = MagicMock()
fake_llm.invoke.return_value = "mock answer"

c = AppContainer(
    settings=RagSettings(search_k=5, rerank_top_k=2),
    vectorstore=fake_vs,
    reranker=fake_reranker,
    llm=fake_llm,
    prompt_builder=lambda q, ctx: "mock prompt",
)

graph = get_graph(container=c)
out = graph.invoke(RAGState(query="hello"))
assert out.answer  # "é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚" ãªã©
æ¬¡ã«ä¸€æ®µã ã‘ä¸Šã’ã‚‹ãªã‚‰ï¼ˆãŠã™ã™ã‚ï¼‰

ã“ã®Containerç‰ˆãŒå…¥ã‚‹ã¨ã€æ¬¡ã¯ã»ã¼ãƒãƒ¼ãƒªã‚¹ã‚¯ã§ä»¥ä¸‹ãŒã§ãã¾ã™ã€‚

Protocol ã§ vectorstore/reranker/llm ã®å‹å¢ƒç•Œã‚’å›ºå®šï¼ˆIDEè£œå®Œãƒ»ä¿å®ˆæ€§UPï¼‰

container.reset() ã‚’ç”¨æ„ã—ã¦ã€ãƒ†ã‚¹ãƒˆå¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç ´æ£„

settings ã‚’ pydantic settings ã«ç½®æ›ï¼ˆç’°å¢ƒå¤‰æ•°æ¤œè¨¼ã‚‚è‡ªå‹•ï¼‰

å¿…è¦ãªã‚‰ã€ã“ã®ã¾ã¾ **Protocolå°å…¥ã¾ã§å«ã‚ãŸâ€œæœ€çµ‚ç‰ˆï¼ˆå‹å¢ƒç•Œã‚¬ãƒã‚¬ãƒï¼‰â€**ã‚‚æç¤ºã—ã¾ã™ã€‚
